% Created 2022-06-27 Mon 14:33
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Svoronos - Kanavas Iason}
\date{\today}
\title{Construction sites SonVis Algorithm documentation}
\hypersetup{
 pdfauthor={Svoronos - Kanavas Iason},
 pdftitle={Construction sites SonVis Algorithm documentation},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.1 (Org mode 9.0.6)},
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Algorithm architecture}
\label{sec:orgfcc3128}
The overall algorithm is structured as:
\begin{enumerate}
\item Interface
\item Sub-processes
\item data processing algorithm
\begin{enumerate}
\item outlier identification,
\item replacement,
\item data-frame creation and manipulation,
\item min-max extraction script
\item datetime re-sample function
\end{enumerate}
\item on-run functions (includes matrix printing functions)
\item IPC inter-process communication (\& connection setup functions)
\item Sonification algorithm
\begin{enumerate}
\item processing functions
\item data receiver -- handler
\item mappings
\item map to scale frequency mapping patch
\begin{enumerate}
\item Map to Lydian scale
\item Map to Beat
\end{enumerate}
\item event receiver - actions
\item synthesisers
\end{enumerate}
\end{enumerate}



\section{Dependencies}
\label{sec:org259fca9}
SuperCollider (sclang has to be in \$PATH)

Python \&
Python packages:

from \uline{\uline{future}} import print\(_{\text{function}}\)
import datetime as dt
import panel as pn
import param  \# for FormatDateRangeSlider
import subprocess  \# to run SC
import threading  \# stop iteration cycle when kill button pressed
\#from pythonosc import udp\(_{\text{client}}\)
from bokeh.models import Slider, CheckboxGroup, CustomJS, Label
import os
import numpy as np
import pandas as pd
import time
import datetime
from dateutil import parser
from pythonosc import udp\(_{\text{client}}\)
import subprocess
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
import sys
from bokeh.plotting import figure
from pythonosc.osc\(_{\text{server}}\) import AsyncIOOSCUDPServer
from pythonosc.dispatcher import Dispatcher
import asyncio

\section{Interface}
\label{sec:org63773c5}
The interface consists of certain visual elements.
The datetime range slider and text input (for the time) are used for date and time accordingly. Using these the user can specify a desired datetime period in the data to sonify and visualise.

\begin{center}
\includegraphics[width=.9\linewidth]{./datetime_selection.png}
\end{center}

The \textbf{start} button is used so that the datetime period is extracted and then sent to be sonified and visualised, while the \textbf{killall} button can interrupt/stop every running procedure in relation to the sonification and visualisation process anytime.

\begin{center}
\includegraphics[width=.9\linewidth]{./start_kill_buttons.png}
\end{center}

Below, there is a checkbox where the user can select the period of the values in the data to re-sample.

\begin{center}
\includegraphics[width=.9\linewidth]{./resample_checkbox.png}
\end{center}

The original collection period is (every) 30 seconds.  The re-sample options are, per minute (T), per 30 minutes (30M), per hour (H), per week (W), per month (M).  In the re-sample function (see below), the data values are derived in every period with selecting the max value when doing the frequency conversion to highlight peaks in the data.  For example, if we want to re-sample with 1 minute re-sample frequency (T). We have initially:
\begin{center}
\begin{tabular}{lr}
\hline
timestamp, & data\\
2021-08-01 00:00:00, & 2\\
2021-08-01 00:00:30, & 0\\
2021-08-01 00:01:00, & 4\\
\hline
\end{tabular}
\end{center}

Re-sample result: The extracted value for the first minute will be "4" because is the max value observed for this minute.

Then, there is a another slider that controls the data iteration frequency and it has a range from 1 to 1000 values per second.

\begin{center}
\includegraphics[width=.9\linewidth]{./values_sec.png}
\end{center}

Finally, there are six buttons where the user can use to turn on/off, the desired data parameters to sonify - visualise

\begin{center}
\includegraphics[width=.9\linewidth]{./synth_onoff.png}
\end{center}

\vspace{0.5em}

Overall, the button python bokeh elements, trigger osc messages that are sent from python to supercollider in order to control different synths.
The ones that utilise this functionality is the \textbf{start} \textbf{killall} and the synth on/off buttons (pm10, pm25, temp, humidity, noise levels, truck count).
This will be elaborated in the IPC section

\section{Sub-processes}
\label{sec:orge035c8e}
On launch, sclang is initialised and runs as a sub-process within the python session.  More specifically, the SuperCollider  patch for sonification is evaluated using the following command in Python.
\begin{verbatim}
# run sonification patch
sclang = subprocess.Popen(
    'sclang particleSonification.scd', shell=True,
    stdout=subprocess.PIPE,
    stderr=subprocess.STDOUT)
\end{verbatim}
Getting back now to the initialisation python script where a function obtains the IP address of the computer using a shell command and then stores it as a global variable.  After that, the OSC client configuration setup uses the variable's value (udp\(_{\text{client}}\) object).  The function is defined the following way as well as the OSC setup.  This process easily configures OSC intercommunication between python and SuperCollider therefore mistakes and hassle by hard-coding IP addresses or manual configurations are avoided.

\begin{verbatim}
# get IP address
def getip():
    global ip
    ip = subprocess.Popen(
        'ipconfig getifaddr en0', shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT)
    ip, _ = ip.communicate()
    ip = ip.decode('utf-8')
    ip = ip.strip()
    print(ip)

# Python osc
getip() # run getip function
client = udp_client.SimpleUDPClient(ip, 57120)
\end{verbatim}
\textbf{Note:} \emph{this works \textbf{only for macOs}.  Therefore it has to be adjusted for linux or windows.}

\vspace{0.2cm}
\noindent
WIN hint:
\begin{verbatim}
ipconfig | grep IPv4 Address.
\end{verbatim}

\section{data processing}
\label{sec:orgf0fd5a6}
In this section the data processing will be described.  The algorithm is developed in Python.  The idea is based on combining and re-constructing the data-sets after the processing results that come out from the derived stats (IQR).  SC has also access to the derived data-set (it is written to disk) so that it has access to the min max values for the correct mapping (see \ref{sec:orgc58e1db}).  In this way, it is also possible to re-use the algorithm with different data since the mapping is not hard-coded.

Outlier identification and replacement was deemed necessary since it was observed by using box-plot stats the PM (both 25 and 10) showed extreme values (far from accurate measurements (140\textasciitilde{} PM10) ) that we would like to exclude.

\begin{center}
\includegraphics[width=.9\linewidth]{./boxplot.png}
\end{center}

Code process:

The very first step is that the original data are loaded from the CSV file while the timestamp column is stored in a variable.  Then the timestamp column is removed from the data-set to do the processing and then added again in the very end of the procedure.

\subsection{outlier identification}
\label{sec:org6d2cf98}
Descriptive statistics are applied in the data-set using the 'describe()' method from pandas.  That is to calculate percentiles, max, min and mean of every column in the data-set.  Then the Q1 and Q3 of PM10 and PM25 are stored in variables.  The IQR of both is calculated as well as the max and min threshold.  The threshold will be used to identify the outliers.  Values that exceed the min and max threshold are the outliers.

\begin{verbatim}
# calculate IQRange for pm_25 from q1 and q3
iqr_pm25 = pm25_q3-pm25_q1
iqr_pm10 = pm10_q3-pm10_q1

# calculate thresholds from IQR -- acc. skewed distribution
# max_thresh: Q3+1.5IQR
# min_thresh: Q1-1.5IQR
max_thresh_pm_25 = pm25_q3+(1.5*iqr_pm25)
min_thresh_pm_25 = pm25_q1-(1.5*iqr_pm25)
max_thresh_pm_10 = pm10_q3+(1.5*iqr_pm10)
min_thresh_pm_10 = pm10_q1-(1.5*iqr_pm10)
thresholds = {'min thresh_pm_25': min_thresh_pm_25,
         'max thresh_pm_25': max_thresh_pm_25,
         'min thresh_pm_10': min_thresh_pm_10,
         'max thresh_pm_10': max_thresh_pm_10}
\end{verbatim}

\subsection{replacement}
\label{sec:org1dde69b}
Values for PM10 and PM25 that exceeded min and max threshold derived from the IQR calculation will be NaN-ed and then replaced with randomly selected samples from the same column in the data-set.  This outlier replacement process takes place for PM10, PM25 and noise levels.  The replacement function also prints how many values were replaced.

\begin{verbatim}
def replaceOutliers(col,minimum_thres,maximum_thres):
    for i in [col]: # replace outliers with nan value
        min = minimum_thres
        max = maximum_thres
        df.loc[df[i] < min, i] = np.nan  # if value is < min_thresh_pm25: nan it
        df.loc[df[i] > max, i] = np.nan  # if value is > max_thresh_pm25: nan it
        df.loc[df[i] == 0, i] = 0.1  # if zero: replace it with 0.1 (smallest val)
        print( # print how many null values are in the specified column
            'sum of null replaced values',
            df[col].isnull().sum())
        global des_col
        des_col = [col] # specify column
\end{verbatim}

\begin{verbatim}
df = df.apply( # replace NaN values from random samples same column
    lambda x: np.where(x.isnull(), x.dropna().sample(len(x), replace=True), x))
\end{verbatim}

\subsection{data-frame creation and manipulation}
\label{sec:orgc42a9f4}
As mentioned the df is first loaded from the CSV file, while the timestamp column is removed and stored in a variable.  This was done to easily process the data-set without interfering with the datetime object (timestamp column).  After that the \ref{sec:org6d2cf98} takes place.  That results to a new data-frame and then the timestamp column is added (insert method).
\begin{verbatim}
# insert timestamp column
df.insert(0, "timestamp", timestamp, True)
\end{verbatim}

Afterwards, the noise level data are loaded and stored in a variable.  The last (cat\(_{\text{24}}\)) column was used.  This column is added to the data-frame that contains everything.  While in the next step the replaceOutliers function is applied to the noise levels column as well ('db').  The threshold that was used aimed to exclude one outlier (5.444976) that was identified by rendering a boxplot from the column data.

Then the truck\(_{\text{count}}\) data are inserted to the main data-frame after the appropriate data processing that is related to the ';' delimiter character splitting. This was done using the pandas data-frame loading process.

\begin{verbatim}
trucks_df = pd.read_csv(  # read truck data file
    "./fake_passage_time.csv",
    delimiter=';')
\end{verbatim}

After that the main data-frame is written to disk within a certain directory path in the current working directory environment.  That would be the \url{./df\_out} directory.
Later the data-frame is registered to a global variable for easier access.

\subsection{min-max extraction script}
\label{sec:orgc58e1db}
The min-max python script was used for use within SuperCollider.  Its purpose is to run the min and max basic python methods to certain columns.  These values will be used for the paramenter mapping.  It returns the min and max value of the specified column.  These are stored in a dictionary.  More information can be found at  \ref{sec:org2dd65e0}.

It takes 2 arguments, these are:
\begin{enumerate}
\item data-file that the min max values will be extracted
\item column in the data-set
\end{enumerate}

It runs from the terminal with the following command.
\begin{verbatim}
python minmax.py data-file column
\end{verbatim}

In SuperCollider this command will run using the "unixCmdGetStdOutLines" method.  It will return the values as "string" in the SuperCollider environment.

\subsection{datetime re-sample function}
\label{sec:orgc402696}
\textbf{Not 100\% implemented}

This function was implemented to re-sample the processed data-frame.  In the non-resampled one the collection frequency is 30s. So, every 30 seconds a new value is stored for all parameters.

While this can of course result to precise estimations regarding events in the data it might not be very convenient if someone would like to quickly listen longer time periods.  For example, with an iteration frequency of 1000 values per second it takes 86.4 seconds time to listen to one day.  This was thought as a limitation and that's why this function was implemented to create down-sampled versions of the main data-set.  Speeding up the iteration frequency was not an option because of computing power limitations.

The frequencies in the re-sampling process that was selected are:
\begin{enumerate}
\item 30S (non re-sampled)
\item T / 1 minute
\item 30M / 30 minutes
\item H / 1 Hour
\item D / 1 Day
\item W / 1 Week
\item M / 1 Month
\end{enumerate}

The re-sample function is accessed by the checkbox on the interface \ref{sec:org63773c5}.  In every re-sample period the maximum value observed is stored.  For example, the non re-sampled data-set has:

\begin{center}
\begin{tabular}{rr}
\hline
00:00:00 & 0\\
00:00:30 & 1\\
00:01:00 & 4\\
\hline
\end{tabular}
\end{center}

If the re-sampling frequency is T (1 min) the 4 value will be stored in this cycle.

\begin{center}
\begin{tabular}{rr}
\hline
00:00:00 & 4\\
\hline
\end{tabular}
\end{center}

Overall, the re-sample function is base on the resample() method in combination with certain conditional tasks so that the correct checkbox element corresponds to the according resample function parameters.  Technically, it is actually divided into two functions.  The first does the conditional argument setting (feeds the correct arguments to the other function) while the other does the actual re-sampling and writes it to disk (CSV).

In the iteration process \ldots{} \textbf{TO BE DONE \& REPORTED}  (Write only re-sampling function related info, next section is: on-run functions)

\section{on-run functions}
\label{sec:org3533e28}
\section{IPC inter-process communication (includes connection setup functions)}
\label{sec:org72be2f1}
The IPC is based on the OSC protocol and its aim is to interconnect Python and SueprCollider.  It is based on sending individual messages from the Python process triggered by the Python interface elements.

In the OSC configuration there are 3 different OSC addresses that allow communication between the two software.  These are:
\begin{enumerate}
\item \label{org9208d00} | main address for the iteration process.  SC received the data values (OSCdef).  Py → SC
\item \label{org9842f5c} | controls the synths, acts like an ON/OFF switch.  Triggered by the 6 synth ON/OFF buttons. Py → SC
\item \label{org4999ba8} | This acts like main ON/OFF switch for the all synths, it is triggered by the START and Killall buttons. Py → SC
\item \label{org49feadf} | Initialisation address, activates the interaction elements on the interface when (or if) the SC responds.  This configuration uses the 1234 port instead. SC → Py
\end{enumerate}

The initial configuration is related to obtaining the IP address of the computer automatically to avoid manual configurations.  This was implemented with the following functions in Python and SuperCollider.

\textbf{Python}

\begin{verbatim}
# get IP address
def getip():
    global ip
    ip = subprocess.Popen(
        'ipconfig getifaddr en0', shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT)
    ip, _ = ip.communicate()
    ip = ip.decode('utf-8')
    ip = ip.strip()
    print(ip)


# Python osc
getip() # run getip function
client = udp_client.SimpleUDPClient(ip, 57120)
\end{verbatim}

To simplify, this function runs
\begin{verbatim}
'ipconfig getifaddr en0'
\end{verbatim}
in the terminal and extracts the current ip address, stores it in a variable and uses it for the OSC UDP client setup.

\textbf{SuperCollider}

On the SC side now the configuration is implemented in the following way
\begin{verbatim}
~ip = ("ipconfig getifaddr en0").unixCmdGetStdOutLines[0]; // get ip
n = NetAddr(~ip, 1234); // set netaddress
n.sendMsg('/startup/',1); // send to python that everything is loaded to enable buttons
("python communication established").postln;
\end{verbatim}

At this point where the above command runs, an OSC message is sent to python using the '\emph{startup}' address.  In the OSC server function (receiver) in Python a task activates the interaction elements on the interface.  This process can be found in the \url{../src/oscServerPython.py} file.

The communication using the \ref{org9208d00} address is the most important one since concerns the iteration process.  The data values in every iteration cycle (row by row) are sent to SuperCollider as shown below.

\begin{verbatim}
client.send_message("/pysc", datetime_selection.iloc[i])
\end{verbatim}
\section{Sonification algorithm}
\label{sec:org2dd65e0}
\subsection{processing functions}
\label{sec:orgd9216ce}
The sonification processing functions are required for the correct mapping of the values.  The aim here is to create a dictionary that contains the min and max values observed in the data for each column.  The first function (stored in the \textasciitilde{}minmax variable) will read and extract the min and max values from the raw data file.  It utilises a python script (\url{../src/minmax.py}) and the unixCmdGetStdOutLines SuperCollider method.  The unixCmdGetStdOutLines will "execute a UNIX command asynchronously using the standard shell (sh)..".  In this case, that would be the evaluation of the minmax.py script along with two arguments, the raw data file path and the desired column.  This takes place in the second function that actually evaluates the previous one and stores the values.  The python script evaluation returns the min and max values while these are being stored in a list for every column (temperature, humidity, noise levels, particles).  Then these values are stored again in a dictionary to be used for the mapping later.  The truck count data min max range were used manually (range: 0 - 9).
\subsection{data receiver -- handler}
\label{sec:org2ae79df}
The data receiver from the SuperCollider side is an OSCdef that uses the "/pysc" address.  The data that are being send are in array type.  The elements of the array are stored in variables (temperature, humidity, pm25, pm10 and numTrucks).  Every time an incoming message is received all data values are being extracted and mapped linearly to a 0.0 - 1.0 scale for further mapping convenience.  Then these values were mapped to the appropriate ones either linearly or exponentially by utilising the min max values from the dictionary (see \ref{sec:orgd9216ce}).
\subsection{mappings}
\label{sec:org0032178}
There is also information on the "documentation" page on the interface.

\begin{itemize}
\item The pm10 and pm25 values were mapped exponentially to a range of 261 - 523 Hz and 1044Hz - 2092Hz for the "warning" sounds and then mapped to the Lydian scale (see \ref{sec:orge64f5a9}).  For the "warning" sounds the values were mapped to pan values (-1) - (-0.5) for the pm10 and 1 - 0.5 for the pm25.  Also, the values were mapped to the ranges 1 - 5 sec, 0.1 - 0.4 (multiplier), 0.0 - 1.0 and for release time, amplitude (warnings) and amplitude of Gendy accordingly.
\item The humidity values were linearly mapped to a range of 1.5 to 3.0 for the "t60" reverb parameter and from 0.5 to 1.5 for the "wet" reverb parameter as well.
\item The noise levels were linearly mapped to the depth of the modulator on a range from 0.0 to 5.0.  The values were also exponentially mapped to a range from 6000 Hz to 18000 Hz of a low pass filter.  They were linearly mapped to frequency values from 120Hz to 520Hz for the main oscillator frequency and as multiplier values for the modulation oscillator mix.  Pulse wave → linear 0.0 - 1.0, Sawtooth-Tri → inverted linear 1.0 - 0.0.
\item The temperature values are not used in the sonification yet
\end{itemize}

The mapping takes place by utilising a dictionary for the synth parameters.  The new values are registered to the dictionary keys and then mapped as synth parameters.
\subsection{map to scale frequency mapping patch}
\label{sec:orge64f5a9}
\subsubsection{Map to Lydian scale}
\label{sec:org4150c8d}
To use a musical scale for the frequency mapping a function was built (\textasciitilde{}mapToScale).  The incoming frequency value is subtracted from each element of a list containing the exact frequencies of the Lydian scale while an ABS is applied to the new list.  After that the smallest value is returned.  In this way the frequency of the Lydian scale that was the closest to the incoming one will be selected.

This function was used for the particle and the truck count data.
\subsubsection{Map to Beat}
\label{sec:orgb0ce56c}
The exact same logic was followed for the Beat mapping as well (noise values).  In this case an array (\textasciitilde{}beatList) containing rhythmic values was used.
\begin{verbatim}
~beatList = [0,2,4,6,8,10,12,14,16,18,20];
\end{verbatim}
\subsection{event receiver - actions}
\label{sec:orgd2ecb34}
Certain actions on the interface trigger OSC messages that were being sent to SuperCollider.  This event receiver is based on two OSCdefs (defined in the \url{../src/parameterReceiver.scd} file).  One is for turning ON \& OFF the appropriate synths according to the active on/off buttons on the interface.  The second one is responding to OSC messages from the "Start" \& "Killall" buttons.  This will start or stop \& mute everything that is currently playing when the buttons are pressed.
\subsection{synthesisers}
\label{sec:orgedc13fc}
All synthesisers are defined in the \url{../src/synthDefs.scd} file, except the one that plays back the truck values \url{../src/trucks.scd}

The general idea is based on a having a master bus mixing all synths to stereo.  The buses were first declared and then used as the "bus" argument in the Out.ar class.  Whenever a synth button on the interface is activated or deactivated the appropriate "gate" parameter in the master synth is set to 1 and 0 accordingly.  First the particles and particle warnings were mixed together and on the derived signal the noise level and truck count synths were added.

This signal is being sent to the reverb that is controlled by the humidity values.  In the output a Limiter was used to prevent signal clipping.

A detailed list of all synthesisers is the following:

\begin{center}
\begin{tabular}{ll}
\hline
main output & \busOut\\
pm10 & x.pm10synth\\
pm25 & x.pm25synth\\
warnings pm 10 & \warning\(_{\text{pm10}}\)\\
warnings pm 25 & \warning\(_{\text{pm25}}\)\\
noise levels & \noiseSynth\\
truck count & \truck (in \url{../src/trucks.scd}\\
humidity & controls busOut reverb parameters\\
\hline
\end{tabular}
\end{center}
\section{Line graphs}
\label{sec:orgbeff4fe}
The Line graphs were implemented using "line" class from Bokeh.  The data-set was necessary to be re-sampled for efficiency and speed.  Otherwise, there were serious issues with CPU overloads.  The data-set was re-sampled with a period of 5 minutes.  In that period the maximum value observed is plotted as a point in the graph.

The pm10 values and pm25 are in the same graph where pm10 are represented with the blue colour while the pm25 with green.  The "olivedrab" colour was selected for the noise values, "indigo" for the humidity and "olive" for the truck count.

It was essential to create a moving box annotation that shows the current date-time that the user listens but also the area in the line graph that is played already.   Transparency is used for the played back area.

The line graphs share common zoom.  So if the user zooms in or out in any graph the rest will respond to the action.
\end{document}
